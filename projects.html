<!DOCTYPE html>
<html lang="en">
	<head>
		<title>Xinge Zhu - Homepage</title>
<meta name="description" content="Dr. Xinge Zhu, PhD in MMLab, the Chinese University of Hong Kong" />
<meta name="keywords" content="Xinge Zhu; MMLab; CUHK; Computer vision; Machine Learning; CVPR; ICCV; Scene Understanding; 3D" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

		<meta name="google-site-verification" 
content="H_f9Itsrdoc8WY1KDH1nc6DQ1-6e_Q23MLPGBO0arHA" />

<script type="text/javascript">
var timeKeeper;

$('#menu').click(function()
{
    $('#bibtex').show();
});

$('#bibtex').click(function()
{
    clearTimeout(timeKeeper);                  
});

$('#menu').focusout(function()
{
    timeKeeper = setTimeout(function() {$('#bibtex').hide()}, 150);
});

$('#menu').attr('tabIndex', -1);
$('#bibtex').hide();
</script>
		<link id="wsite-base-style" rel="stylesheet" type="text/css" href="https://cdn2.editmysite.com/css/sites.css?buildTime=1234" />
<link rel="stylesheet" type="text/css" href="https://cdn2.editmysite.com/css/old/fancybox.css?1234" />
<link rel="stylesheet" type="text/css" href="files/main_style.css?1530535589" title="wsite-theme-css" />

<link href='https://fonts.googleapis.com/css?family=Yantramanav:400,300,700&subset=latin,latin-ext' rel='stylesheet' type='text/css' />
<style type='text/css'>
.wsite-elements.wsite-not-footer:not(.wsite-header-elements) div.paragraph, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) p, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-block .product-title, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-description, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .wsite-form-field label, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .wsite-form-field label, #wsite-content div.paragraph, #wsite-content p, #wsite-content .product-block .product-title, #wsite-content .product-description, #wsite-content .wsite-form-field label, #wsite-content .wsite-form-field label, .blog-sidebar div.paragraph, .blog-sidebar p, .blog-sidebar .wsite-form-field label, .blog-sidebar .wsite-form-field label {font-family:"Times New Roman" !important;}
#wsite-content div.paragraph, #wsite-content p, #wsite-content .product-block .product-title, #wsite-content .product-description, #wsite-content .wsite-form-field label, #wsite-content .wsite-form-field label, .blog-sidebar div.paragraph, .blog-sidebar p, .blog-sidebar .wsite-form-field label, .blog-sidebar .wsite-form-field label {}
.wsite-elements.wsite-footer div.paragraph, .wsite-elements.wsite-footer p, .wsite-elements.wsite-footer .product-block .product-title, .wsite-elements.wsite-footer .product-description, .wsite-elements.wsite-footer .wsite-form-field label, .wsite-elements.wsite-footer .wsite-form-field label{}
.wsite-elements.wsite-not-footer:not(.wsite-header-elements) h2, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-long .product-title, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-large .product-title, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-small .product-title, #wsite-content h2, #wsite-content .product-long .product-title, #wsite-content .product-large .product-title, #wsite-content .product-small .product-title, .blog-sidebar h2 {font-family:"Times New Roman" !important;}
#wsite-content h2, #wsite-content .product-long .product-title, #wsite-content .product-large .product-title, #wsite-content .product-small .product-title, .blog-sidebar h2 {}
.wsite-elements.wsite-footer h2, .wsite-elements.wsite-footer .product-long .product-title, .wsite-elements.wsite-footer .product-large .product-title, .wsite-elements.wsite-footer .product-small .product-title{}
#wsite-title {color:#515151 !important;}
.wsite-not-footer h2.wsite-content-title a, .wsite-not-footer .paragraph a, .wsite-not-footer blockquote a, #blogTable .blog-sidebar a, #blogTable .blog-comments a, #blogTable .blog-comments-bottom a, #wsite-com-store a, #wsite-com-product-gen a {color:#052ef3 !important;}
.wsite-menu-default a {font-family:"Yantramanav" !important;text-transform:  none !important;letter-spacing: 0px !important;}
.wsite-menu a {}
.wsite-image div, .wsite-caption {}
.galleryCaptionInnerText {}
.fancybox-title {}
.wslide-caption-text {}
.wsite-phone {}
.wsite-headline,.wsite-header-section .wsite-content-title {}
.wsite-headline-paragraph,.wsite-header-section .paragraph {}
.wsite-button-inner {}
.wsite-not-footer blockquote {}
.wsite-footer blockquote {}
.blog-header h2 a {}
#wsite-content h2.wsite-product-title {}
.wsite-product .wsite-product-price a {}
.wsite-not-footer h2.wsite-content-title a:hover, .wsite-not-footer .paragraph a:hover, .wsite-not-footer blockquote a:hover, #blogTable .blog-sidebar a:hover, #blogTable .blog-comments a:hover, #blogTable .blog-comments-bottom a:hover, #wsite-com-store a:hover, #wsite-com-product-gen a:hover {color:#8d2424 !important;}
@media screen and (min-width: 767px) {.wsite-elements.wsite-not-footer:not(.wsite-header-elements) div.paragraph, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) p, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-block .product-title, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-description, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .wsite-form-field label, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .wsite-form-field label, #wsite-content div.paragraph, #wsite-content p, #wsite-content .product-block .product-title, #wsite-content .product-description, #wsite-content .wsite-form-field label, #wsite-content .wsite-form-field label, .blog-sidebar div.paragraph, .blog-sidebar p, .blog-sidebar .wsite-form-field label, .blog-sidebar .wsite-form-field label {line-height:20px !important;}
#wsite-content div.paragraph, #wsite-content p, #wsite-content .product-block .product-title, #wsite-content .product-description, #wsite-content .wsite-form-field label, #wsite-content .wsite-form-field label, .blog-sidebar div.paragraph, .blog-sidebar p, .blog-sidebar .wsite-form-field label, .blog-sidebar .wsite-form-field label {}
.wsite-elements.wsite-footer div.paragraph, .wsite-elements.wsite-footer p, .wsite-elements.wsite-footer .product-block .product-title, .wsite-elements.wsite-footer .product-description, .wsite-elements.wsite-footer .wsite-form-field label, .wsite-elements.wsite-footer .wsite-form-field label{}
.wsite-elements.wsite-not-footer:not(.wsite-header-elements) h2, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-long .product-title, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-large .product-title, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-small .product-title, #wsite-content h2, #wsite-content .product-long .product-title, #wsite-content .product-large .product-title, #wsite-content .product-small .product-title, .blog-sidebar h2 {font-size:16px !important;}
#wsite-content h2, #wsite-content .product-long .product-title, #wsite-content .product-large .product-title, #wsite-content .product-small .product-title, .blog-sidebar h2 {}
.wsite-elements.wsite-footer h2, .wsite-elements.wsite-footer .product-long .product-title, .wsite-elements.wsite-footer .product-large .product-title, .wsite-elements.wsite-footer .product-small .product-title{}
#wsite-title {font-size:22px !important;}
.wsite-menu-default a {font-size:15.5px !important;}
.wsite-menu a {}
.wsite-image div, .wsite-caption {}
.galleryCaptionInnerText {}
.fancybox-title {}
.wslide-caption-text {}
.wsite-phone {}
.wsite-headline,.wsite-header-section .wsite-content-title {}
.wsite-headline-paragraph,.wsite-header-section .paragraph {}
.wsite-button-inner {}
.wsite-not-footer blockquote {}
.wsite-footer blockquote {}
.blog-header h2 a {}
#wsite-content h2.wsite-product-title {}
.wsite-product .wsite-product-price a {}
}</style>

		<script>
var STATIC_BASE = '//cdn1.editmysite.com/';
var ASSETS_BASE = '//cdn2.editmysite.com/';
var STYLE_PREFIX = 'wsite';
</script>
<script src='https://ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js'></script>

<script type="text/javascript" src="https://cdn2.editmysite.com/js/lang/en/stl.js?buildTime=1234&"></script>
<script src="https://cdn2.editmysite.com/js/site/main.js?buildTime=1234"></script><script type="text/javascript">
		function initCustomerAccountsModels() {
					(function(){_W.setup_rpc({"url":"\/ajax\/api\/JsonRPC\/CustomerAccounts\/","actions":{"CustomerAccounts":[{"name":"login","len":2,"multiple":false,"standalone":false},{"name":"logout","len":0,"multiple":false,"standalone":false},{"name":"getSessionDetails","len":0,"multiple":false,"standalone":false},{"name":"getAccountDetails","len":0,"multiple":false,"standalone":false},{"name":"getOrders","len":0,"multiple":false,"standalone":false},{"name":"register","len":4,"multiple":false,"standalone":false},{"name":"emailExists","len":1,"multiple":false,"standalone":false},{"name":"passwordReset","len":1,"multiple":false,"standalone":false},{"name":"passwordUpdate","len":3,"multiple":false,"standalone":false},{"name":"validateSession","len":1,"multiple":false,"standalone":false}]},"namespace":"_W.CustomerAccounts.RPC"});
_W.setup_model_rpc({"rpc_namespace":"_W.CustomerAccounts.RPC","model_namespace":"_W.CustomerAccounts.BackboneModelData","collection_namespace":"_W.CustomerAccounts.BackboneCollectionData","bootstrap_namespace":"_W.CustomerAccounts.BackboneBootstrap","models":{"CustomerAccounts":{"_class":"CustomerAccounts.Model.CustomerAccounts","defaults":null,"validation":null,"types":null,"idAttribute":null,"keydefs":null}},"collections":{"CustomerAccounts":{"_class":"CustomerAccounts.Collection.CustomerAccounts"}},"bootstrap":[]});
})();
		}
		if(document.createEvent && document.addEventListener) {
			var initEvt = document.createEvent('Event');
			initEvt.initEvent('customerAccountsModelsInitialized', true, false);
			document.dispatchEvent(initEvt);
		} else if(document.documentElement.initCustomerAccountsModels === 0){
			document.documentElement.initCustomerAccountsModels++
		}
		</script>
		<script type="text/javascript"> _W = _W || {}; _W.securePrefix='UNSET'; </script><script>_W = _W || {};
			_W.customerLocale = "en_US";
			_W.storeName = null;
			_W.storeCountry = "NL";
			_W.storeCurrency = "USD";
			_W.storeEuPrivacyPolicyUrl = "";
			com_currentSite = "100730443961222929";
			com_userID = "30604459";</script><script type="text/javascript">_W.configDomain = "www.weebly.com";</script><script>_W.relinquish && _W.relinquish()</script>
<script type="text/javascript" src="https://cdn2.editmysite.com/js/lang/en/stl.js?buildTime=1234&"></script><script> _W.themePlugins = [];</script><script type="text/javascript"> _W.recaptchaUrl = "https://www.google.com/recaptcha/api.js"; </script><script type="text/javascript"> window._W = window._W || {}; _W.showV2Footer = 0; </script><script type="text/javascript"><!--
	var IS_ARCHIVE = 1;
	
	function initFlyouts(){
		initPublishedFlyoutMenus(
			[{"id":"871451071371970207","title":"Home","url":"index.html","target":"","nav_menu":false,"nonclickable":false},
				{"id":"605036677414579087","title":"People","url":"https:\/\/people.html","target":"","nav_menu":false,"nonclickable":false},
				{"id":"605036677414579077","title":"Publications","url":"https:\/\/publications.html","target":"","nav_menu":false,"nonclickable":false}
				{"id":"605036677414579107","title":"Research","url":"https:\/\/projects.html","target":"","nav_menu":false,"nonclickable":false}
				{"id":"605036677414579097","title":"Activities","url":"https:\/\/activities.html","target":"","nav_menu":false,"nonclickable":false}
				{"id":"605036677414579117","title":"Positions","url":"https:\/\/positions.html","target":"","nav_menu":false,"nonclickable":false}

				],
			"871451071371970207",
			'',
			'active',
			false,
			{"navigation\/item":"<li {{#id}}id=\"{{id}}\"{{\/id}} class=\"wsite-menu-item-wrap\">\n\t<a\n\t\t{{^nonclickable}}\n\t\t\t{{^nav_menu}}\n\t\t\t\thref=\"{{url}}\"\n\t\t\t{{\/nav_menu}}\n\t\t{{\/nonclickable}}\n\t\t{{#target}}\n\t\t\ttarget=\"{{target}}\"\n\t\t{{\/target}}\n\t\t{{#membership_required}}\n\t\t\tdata-membership-required=\"{{.}}\"\n\t\t{{\/membership_required}}\n\t\tclass=\"wsite-menu-item\"\n\t\t>\n\t\t{{{title_html}}}\n\t<\/a>\n\t{{#has_children}}{{> navigation\/flyout\/list}}{{\/has_children}}\n<\/li>\n","navigation\/flyout\/list":"<div class=\"wsite-menu-wrap\" style=\"display:none\">\n\t<ul class=\"wsite-menu\">\n\t\t{{#children}}{{> navigation\/flyout\/item}}{{\/children}}\n\t<\/ul>\n<\/div>\n","navigation\/flyout\/item":"<li {{#id}}id=\"{{id}}\"{{\/id}}\n\tclass=\"wsite-menu-subitem-wrap {{#is_current}}wsite-nav-current{{\/is_current}}\"\n\t>\n\t<a\n\t\t{{^nonclickable}}\n\t\t\t{{^nav_menu}}\n\t\t\t\thref=\"{{url}}\"\n\t\t\t{{\/nav_menu}}\n\t\t{{\/nonclickable}}\n\t\t{{#target}}\n\t\t\ttarget=\"{{target}}\"\n\t\t{{\/target}}\n\t\tclass=\"wsite-menu-subitem\"\n\t\t>\n\t\t<span class=\"wsite-menu-title\">\n\t\t\t{{{title_html}}}\n\t\t<\/span>{{#has_children}}<span class=\"wsite-menu-arrow\">&gt;<\/span>{{\/has_children}}\n\t<\/a>\n\t{{#has_children}}{{> navigation\/flyout\/list}}{{\/has_children}}\n<\/li>\n"},
			{}
		)
	}
//-->
</script>
		
		
	</head>
	<body class=" no-header-page  wsite-theme-light  wsite-page-index"><div id="container">
	<table id="header">
		<tr>
			<td id="logo"><span class="wsite-logo">

	
	<span class="wsite-title-placeholder">&nbsp;</span><span style="display:none">
	<span style="display:none">Xinge Zhu's Research Page!</span>
	</span>
	

</span></td>
			<td id="header-right">
				<table>
					<tr>
						<td class="phone-number"></td>
						<td class="social"></td>
						<td class="search"></td>
					</tr>
				</table>
			</td>
		</tr>
	</table>
	<div id="navigation">
		<div id="nav-r">
			<div id="nav-content">
				<ul class="wsite-menu-default">
						<li id="871451071371970207" class="wsite-menu-item-wrap">
							<a
										href="index.html"
								class="wsite-menu-item"
								>
								Home
							</a>
							
						</li>
						<li id="pg605036677414579077" class="wsite-menu-item-wrap">
							<a
										href="publications.html"
								class="wsite-menu-item"
								>
								Publications
							</a>
							
						</li>
						<li id="pg605036677414579097" class="wsite-menu-item-wrap">
							<a
										href="activity.html"
								class="wsite-menu-item"
								>
								Activities
							</a>
							
						</li>

				</ul>
				<div class="clear"></div>
			</div>
		</div>
	</div>
	<div id="main">
		<div id="banner-bot">
			<div id="banner-top">
				<div id="banner">
					<div class="wsite-header"></div>
					<em id="tl"></em>
					<em id="tr"></em>
					<em id="bl"></em>
					<em id="br"></em>
				</div>
			</div>
		</div>
		<div id="content">
			<div id="wsite-content" class="wsite-elements wsite-not-footer">
	<div><div class="wsite-multicol"><div class="wsite-multicol-table-wrap" style="margin:0 -15px;">
	<table class="wsite-multicol-table">
		<tbody class="wsite-multicol-tbody">
			<tr class="wsite-multicol-tr">
				<td class="wsite-multicol-col" style="width:33.818493150685%; padding:0 15px;">
					

<h2 class="wsite-content-title" style="text-align:left;"><font size="5">Projects</font></h2>

<div><div style="height: 10px; overflow: hidden; width: 95%;"></div>
<hr class="styled-hr" style="width:100%;"></hr>
<div style="height: 10px; overflow: hidden; width: 100%;"></div></div>


<style>
html {
  box-sizing: border-box;
}

*, *:before, *:after {
  box-sizing: inherit;
}

.column {
  float: left;
  width: 50%;
  margin-bottom: 16px;
  padding: 0px 3% 0px 0px;
}


@media screen and (max-width: 650px) {
  .column {
    width: 100%;
    display: block;
  }
}

.card {
  box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2);
  text-align:center;
}

.container {
  padding: 4px 4px 4px 4px;
}

.container::after, .row::after {
  content: "";
  clear: both;
  display: table;
  text-align: left;
}

.title {
  color: grey;
}

/*.button {
  border: none;
  outline: 0;
  display: inline-block;
  padding: 8px;
  color: white;
  background-color: #022b59;
  text-align: center;
  cursor: pointer;
  width: 100%;
}

.button:hover {
  background-color: #555;
}*/

.outer{display:flex;
justify-content:center}

/*.center {
  display: block;
  margin-left: auto;
  margin-right: auto;
}*/

.fill {
    display: flex;
    justify-content: center;
    align-items: center;
    overflow: hidden
}

.textblock {
  display: inline-block;
  width: 100%;
  height: 156px;
  padding: 5px;
/*  border: 1px solid blue;
  background-color: yellow;*/
}

</style>

<!-- <div id="postgraduates" class="paragraph" style="text-align:left;"><font size="4"><strong>Postgraduate Students</strong></font></div> -->
<div class="row">
  <div class="column">
    <div class="card">
    	<div class="paragraph" style="text-align:left;"><font size="4"><strong>Supervised/Self-Supervised Scene Depth Estimation</strong></font></div>

        <div>
            <iframe width=100% height="315" src="https://www.youtube.com/embed/Ql26T71IOfM" frameborder="0" allow="autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>  
      <div class="container">
      	<div class="textblock">
        	<p class="title" style="text-align:justify;font-size:110%">Depth is a fundamental element for the machine to perceive and understand the scene. While estimating the depth of a scene from a single image is a natural ability for humans, devising computational models for accurately predicting depth information from RGB data is a challenging task. In particular, recent works have achieved remarkable performance thanks to powerful deep learning models. In a supervised setting, assuming the availability of a large training set of RGB-depth pairs, monocular depth prediction is casted as a pixel-level regression problem and Convolutional Neural Network (CNN) architectures are typically employed. While for a unsupervised/self-supervised setting, videos are usually considered to learn the matching between temproal video frames with predicted scene depth, camera pose and/or intrinsic parameters. </p>
        </div>
       	<p style="text-align:left;"><font color="blue" ><strong>Projects and Codes</strong></font></p>
        <p><button class="button" style="width: fit-content; float:left; margin-right:10px; margin-bottom:5px; font-size:100%;"><a style="color:black" href="https://github.com/danxuhk/ContinuousCRF-CNN" target="_blank">Deep MS-CRF</a></button><button class="button" style="width: fit-content; float:left; margin-right:10px; margin-bottom:5px; font-size:100%;"><a style="color:black" href="https://github.com/danxuhk/StructuredAttentionDepthEstimation" target="_blank">Structured Attention Network</a></button><button class="button" style="width: fit-content; float:left; align=left; margin-right:10px; margin-bottom:5px; font-size:100%;"><a style="color:black" href="https://github.com/andrea-pilzer/unsup-stereo-depthGAN" target="_blank">Cycle Adversarial DepthNet</a></button></p>
      </div>
  </div>
</div>
  <div class="column">
    <div class="card">
    	<div class="paragraph" style="text-align:left;"><font size="4"><strong>Joint Deep Multi-task Learning for Scene Understanding</strong></font></div>	
        <div>
            <iframe width=100% height="315" src="https://www.youtube.com/embed/PjcF25FgJ94" frameborder="0" allow="autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>  
      <div class="container">
      	<div class="textblock">
        	<p class="title" style="text-align:justify;font-size:110%">Typical deep multi-task learning approaches mainly focused on the final prediction level via employing the crossmodal interactions to mutually refining the tasks [18, 51] or
			designing more effective joint-optimization objective functions. These methods directly learn to predict the two tasks given the same input training data. However, simultaneously learning the different tasks using distinct loss
			functions makes the network optimization complicated, and it is generally not easy to obtain a good generalization ability for all the tasks. we explore multi-task deep learning by jointly learning a set of intermediate auxiliary tasks ranging from low level to high level, and then the predictions from these intermediate auxiliary tasks are utilized as multi-modal input for the final tasks. </p>
        </div>
       		<p style="text-align:left;"><font color="blue" ><strong>Projects and Codes</strong></font></p>
        	<p><button type="button" style="width: fit-content; float:left; font-size:100%; margin-right:10px; margin-bottom:5px;"><a style="color:black" href="https://arxiv.org/abs/1805.04409" target="_blank">PAD-Net</a></button></p>
      </div>
  </div>
</div>
</div>


<!--<div class="row">-->
<!--  <div class="column">-->
<!--    <div class="card">-->
<!--    	<div class="paragraph" style="text-align:left;"><font size="4"><strong>Deep Visual SLAM</strong></font></div>-->

<!--        <div>-->
<!--            <iframe width=100% height="315" src="https://www.youtube.com/embed/3YdxjRp2GGI" frameborder="0" allow="autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>-->
<!--        </div>  -->
<!--      <div class="container">-->
<!--      	<div class="textblock">-->
<!--        	<p class="title" style="text-align:justify;font-size:110%">End-to-end deep visual SLAM is an important research domain for a wide range of applications in computer vision and robotics. Visual SLAM involves high-level scene understanding problems integrating data and tasks from 2D and 3D perspectives. high-level scene understanding typically involves multiple different tasks in both 2D and 3D domains. In 2D, common tasks include object detection, segmentation, tracking based on image or video data. In 3D, we need to deal with tasks such as 2.5D depth estimation, 3D point cloud regression and spatial-temporal map construction and localization. These different tasks and data sources could be integrated into a single deep framework and finally contribute to a joint end-to-end high-level scene understanding framework. </p>-->
<!--        </div>-->
<!--       	<p style="text-align:left;"><font color="blue" ><strong>Projects and Codes</strong></font></p>-->
<!--        <p><button class="button" style="width: fit-content; float:left; font-size:100%; margin-right:10px; margin-bottom:5px;"><a style="color:black" href="tt" target="_blank">Deep Unsupervised Moving SLAM</a></button></p>-->
<!--      </div>-->
<!--  </div>-->
<!--</div>-->

<!--  <div class="column">-->
<!--    <div class="card">-->
<!--    	<div class="paragraph" style="text-align:left;"><font size="4"><strong>Joint Video Object Detection and Tracking</strong></font></div>	-->
<!--        <div>-->
<!--            <iframe width=100% height="315" src="https://www.youtube.com/embed/U_ejNiyc96Y" frameborder="0" allow="autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>-->
<!--        </div>  -->
<!--      <div class="container">-->
<!--      	<div class="textblock">-->
<!--        	<p class="title" style="text-align:justify;font-size:110%">Multiple object tracking and video object detection are fundamental tasks in intelligent scene understanding. We explore to build a joint framework to model the interaction between these two tasks in both the feature and the prediction level, in order to effectively refine each other from inherent spatial and temporal relationships. Our work targets deriving the scene depth information from the RGB data, and thus does not require additional depth sensors other than-->
<!--			standard RGB cameras. One of our works aimed to explore using scene geometry for the task of video object detection in CNN. Instead of estimating accurate 3D geometry, we consider deriving and utilizing scene-specific geometry, and enforce the convolutional operations to be conditioned on the object scales and positions, leading to a geometry-aware deep learning.</p>-->
<!--        </div>-->
<!--       	<p style="text-align:left;"><font color="blue" ><strong>Projects and Codes</strong></font></p>-->

<!--        <p><button class="button" style="width: fit-content; float:left; font-size:100%; margin-right:10px; margin-bottom:5px;"><a style="color:black" href="https://www.robots.ox.ac.uk/~danxu/uploads/2019/0218.pdf" target="_blank">Geometry-Aware GAST-Net</a></button></p>-->
<!--      </div>-->
<!--  </div>-->
<!--</div>-->
<!--</div>-->


<!--<div class="row">-->
<!--  <div class="column">-->
<!--    <div class="card" style="align-items: center">-->
<!--    	<div class="paragraph" style="text-align:left;"><font size="4"><strong>Statistical Deep Learning</strong></font></div>-->
<!--        <div class="fill">-->
<!--            <img class="iconDetails" src="uploads/research/dynamicgraph.gif" alt="Card image cap" width=68% height="315">-->
<!--        </div>  -->
<!--      <div class="fill" height=250%> -->
<!--      	<div class="container">-->
<!--      		<div class="textblock">-->
<!--        		<p class="title" style="text-align:justify;font-size:110%">Another focus of my current research is statistical-based structured representation learning from both the performance and the computational complexity. Large-scale graph based deep learning models and theory. Probabilistic graph models have been widely studied by researchers to model structural and interdependent data in traditional non-deep machine learning. However, applying probabilistic models to understand deep learning in a principled means, and developing novel theoretic statistical inference strategies to further improve the performance of the deep learning are still in their infancy. The deep network can essentially be treated as a large-scale graph, and the research on the statistical graph theory with deep graph network would be remarkably beneficial in the development of new deep learning technologies. We conduct experiments on different challenging tasks, i.e. scene parsing on Cityscapes, instance segmentation and object detection on COCO, and on different strong backbone networks, demonstrating the generalisability and the effectiveness of deep graph models.  </p>-->
<!--        	</div>-->
<!--       		<p style="text-align:left;"><font color="blue" ><strong>Projects and Codes</strong></font></p>-->
<!--        	<p><button class="button" style="width: fit-content; float:left; font-size:100%; margin-right:10px; margin-bottom:5px;"><a style="color:black" href="https://www.robots.ox.ac.uk/~lz/dgmn/" target="_blank">Dynamic Graph Network</a></button><button class="button" style="width: fit-content; float:left; font-size:100%; margin-right:10px; margin-bottom:5px;"><a style="color:black" href="tt" target="_blank">Probabilistic Graph Attention Network</a></button></p>-->
<!--    	</div>-->
<!--      </div>-->
<!--  </div>-->
<!--</div>-->
<!--  <div class="column">-->
<!--    <div class="card" style="align-items: center">-->
<!--    	<div class="paragraph" style="text-align:left;"><font size="4"><strong>Cross-domain image translation</strong></font></div>-->
<!--        <div class="fill">-->
<!--            <img class="iconDetails" src="uploads/research/image2image.gif" alt="Card image cap" width=95% height="315">-->
<!--        </div>  -->
<!--      <div class="fill" height=250%> -->
<!--      	<div class="container">-->
<!--      		<div class="textblock">-->
<!--        		<p class="title" style="text-align:justify;font-size:110%">Semantic-guided scene generation is a hot research topic-->
<!--				covering several main-stream research directions, including-->
<!--				cross-view image translation and-->
<!--				semantic image synthesis. The cross-view-->
<!--				image translation task proposed in is essentially an illposed problem due to the large ambiguity in the generation-->
<!--				if only a single RGB image is given as input. To alleviate-->
<!--				this problem, recent works such as SelectionGAN try-->
<!--				to generate the target image based on an image of the scene-->
<!--				and several novel semantic maps. Adding a semantic map allows the model to learn the-->
<!--				correspondences in the target view with appropriate object-->
<!--				relations and transformations. On the other side, the semantic image synthesis task aims to generate a photo-realistic image from a semantic map. With the useful semantic information, existing methods on both tasks achieved promising performance in scene generation. However, one can still observe unsatisfying perspectives,-->
<!--				especially on the generation of local scene structure and details as well as small scale objects. </p>-->
<!--        	</div>-->
<!--       		<p style="text-align:left;"><font color="blue" ><strong>Projects and Codes</strong></font></p>-->
<!--        	<p><button class="button" style="width: fit-content; float:left; font-size:100%; margin-right:10px; margin-bottom:5px;"><a style="color:black" href="https://disi.unitn.it/~hao.tang/project/SelectionGAN.html" target="_blank">SelectionGAN</a></button><button class="button" style="width: fit-content; float:left; font-size:100%; margin-right:10px; margin-bottom:5px;"><a style="color:black" href="https://github.com/Ha0Tang/LGGAN" target="_blank">LGGAN</a></button></p>-->
<!--    	</div>-->
<!--      </div>-->
<!--  </div>-->
<!--</div>-->
<!--</div>-->

<!-- <div class="paragraph" style="text-align:left;"><font size="4"><strong>Supervised/Self-Supervised Scene Depth Estimation</strong> -->

<!--     <div class='card-horizontal' style="width:80%">
        <div>
            <iframe width="560" height="315" src="https://www.youtube.com/embed/4jVMvV2YgaU?autoplay=1" frameborder="0" allow="autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>  
        <div style='margin-left:1%;'></div>
        <div class='container3' style="width:50%">
        	<h2 class="card-body">Prof. Dr. Xinge Zhu</h2>
        	<p class="title">Depth is a fundamental element for the machine to perceive and understand the scene. While estimating the depth of a scene from a single image is a natural ability for humans, devising computational models for accurately predicting depth information from RGB data is a challenging task. In particular, recent works have achieved remarkable performance thanks to powerful deep learning models. In a supervised setting, assuming the availability of a large training set of RGB-depth pairs, monocular depth prediction is casted as a pixel-level regression problem and Convolutional Neural Network (CNN) architectures are typically employed. While for a unsupervised/self-supervised setting, videos are usually considered to learn the matching between temproal video frames with predicted scene depth, camera pose and/or intrinsic parameters. </p>
        	<p><font color="blue">Computer Vision and Deep Learning</font></p>
        	<p><strong>Email:</strong> danxuhk AT gmail DOT com</p>
        	<p><button class="button" style="width:25%"><a style="color:white" href="index.html">Homepage</a></button></p>
		</div>
	</div> -->

<!-- <div class="paragraph" style="text-align:left;"><font size="4"><strong>Deep Multi-task Learning for Scene Understanding</strong>

    <div class='card-horizontal' style="width:100%">
        <div>
            <iframe width="560" height="315" src="https://www.youtube.com/embed/4jVMvV2YgaU?autoplay=1" frameborder="0" allow="autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>  
        <div style='margin-left:1%;'></div>
        <div class='container3' style="width:50%">
        	<h2 class="card-title">Prof. Dr. Xinge Zhu</h2>
        	<p class="title"><strong>Director & PI</strong></p>
        	<p><font color="blue">Computer Vision and Deep Learning</font></p>
        	<p><strong>Email:</strong> danxuhk AT gmail DOT com</p>
        	<p><button class="button" style="width:95%"><a style="color:white" href="index.html">Homepage</a></button></p>
		</div>
	</div> -->

<!-- <div class="paragraph" style="text-align:left;"><font size="4"><strong>Deep SLAM</strong>

    <div class='card-horizontal' style="width:100%">
        <div>
            <iframe width="560" height="315" src="https://www.youtube.com/embed/4jVMvV2YgaU?autoplay=1" frameborder="0" allow="autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>  
        <div style='margin-left:1%;'></div>
        <div class='container3' style="width:50%">
        	<h2 class="card-title">Prof. Dr. Xinge Zhu</h2>
        	<p class="title"><strong>Director & PI</strong></p>
        	<p><font color="blue">Computer Vision and Deep Learning</font></p>
        	<p><strong>Email:</strong> danxuhk AT gmail DOT com</p>
        	<p><button class="button" style="width:95%"><a style="color:white" href="index.html">Homepage</a></button></p>
		</div>
	</div> -->

<div><div style="height: 10px; overflow: hidden; width: 100%;"></div>
<hr class="styled-hr" style="width:100%;"></hr>
<div style="height: 10px; overflow: hidden; width: 100%;"></div></div>

<div class="paragraph" style="text-align:center;"><font size="2"><font color="#626262">&copy; 2015 by Xinge Zhu. All Rights Reserved.<strong>&nbsp;</strong>L</font><span style=""><font color="#626262">ast Modified: 08/07/2015</font></span></font><font size="2"><span style=""><br /></span></font></div>

<div><div id="973426107240231346" align="center" style="width: 100%; overflow-y: hidden;" class="wcustomhtml"><!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=10627532; 
var sc_invisible=0; 
var sc_security="4bf6f1aa"; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "https://www.");
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script>
<noscript><div class="statcounter"><a title="shopify stats"
href="https://statcounter.com/shopify/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/10627532/0/4bf6f1aa/0/"
alt="shopify stats"></a></div></noscript>

<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=fcfbff&w=150&t=n&d=3eBmi1qebjNIRpKdLeuKOzZQKM1GqN3tshV3B4UD_yk&co=0b4975&cmo=3acc3a&cmn=ff5353&ct=cdd4d9'></script>
<!-- End of StatCounter Code for Default Guide --></div>



<!--</div>-->
<!--</div>-->

<!--			<div class="clear"></div>-->
<!--		</div>-->
<!--	</div>-->
<!--	<div id="footer">-->
<!--		<div id="footer-right">-->
<!--			Create a <a target="_top" href="https://www.robots.ox.ac.uk/~danxu">free web site</a> with <a target="_top" href="https://www.robots.ox.ac.uk/~danxu/" title="бесплатный сайт">Weebly</a>-->
<!--		</div>-->
<!--		<div class="clear"></div>-->
<!--	</div>-->
<!--</div>-->
<!--    <div id="customer-accounts-app"></div>-->
<!--    <script src="https://cdn2.editmysite.com/js/site/main-customer-accounts-site.js?buildTime=1234"></script>-->

<!--		-->
<!--	</body>-->
</html>
